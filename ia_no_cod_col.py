# -*- coding: utf-8 -*-
"""IA_No_Cod_Col.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kfmJaG6u-LWKOGSPZPqL6SeTL0WdqGdw

#Importar librerías
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

from sklearn.model_selection import train_test_split, GridSearchCV, PredefinedSplit
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.svm import SVC, SVR
from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score, classification_report, confusion_matrix, accuracy_score, mean_squared_error, mean_absolute_error, r2_score
from sklearn.linear_model import LinearRegression
import xgboost as xgb
from xgboost import XGBRegressor
import time
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.neural_network import MLPRegressor
import xgboost as xgb

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam

from google.colab import drive
drive.mount('/content/drive')

def histogramas(dataset):
  # Histogramas con la libreria matplotlib
  n = 0
  for m in dataset:
    plt.figure(n, figsize=(8,5))
    plt.grid()
    sns.histplot(dataset.iloc[:, n], kde = True, bins=20)
    plt.ylabel("Frecuencia",font= font_l)
    plt.xticks(font= font_l)
    plt.title(str(dataset.columns[n]), fontdict = font_e)
    n += 1

def estadisticas(dataset):
  # Calculo de estadisticas utilizando la libreria numpy
  promedio = np.mean(dataset, axis = 0)
  mediana = np.median(dataset, axis = 0)
  valor_min = np.min(dataset, axis = 0)
  valor_max = np.max(dataset, axis = 0)
  desviacion_estandar = np.std(dataset, axis = 0)
  # Creacion de base de datos que contenga lo calculado anteriomente
  estadisticas = pd.DataFrame(
                list(zip(promedio, mediana, valor_min, valor_max,
                         desviacion_estandar)),
                index = list(dataset.columns),
                columns = ['promedio', 'mediana', 'valor minimo',
                           'valor maximo', 'desviacion estandar'])

  return estadisticas

"""#Se lee el Dataset"""

file_path = '/content/drive/MyDrive/dataset.csv'
spotify_data = pd.read_csv(file_path, delimiter = ',')

spotify_data.head(3)

"""#Se eliminan las columnas que no aportan al modelo de predicción"""

spotify_data = spotify_data.dropna()

track_genre = spotify_data['track_genre']
popularity = spotify_data['popularity']
artists = spotify_data['artists']

spotify_data = spotify_data.drop(['Unnamed: 0','track_id','artists','album_name','track_name', 'time_signature','track_genre'], axis=1)

spotify_data['explicit'] = spotify_data['explicit'].apply(lambda explicit: 0 if explicit == False else 1)

spotify_data.head(3)

spotify_data.head(3)

"""#Se plotea la matriz de correlaciones"""

font_e = {'family': 'serif','color': 'darkblue','weight': 'normal','size': 12,}
font_l = {'family': 'serif','size': 9,}

spotify_data_corr = spotify_data.copy()
matriz_corr = spotify_data_corr.corr().abs()

plt.figure(figsize=(10, 5))
sns.heatmap(matriz_corr, annot=True, fmt=".2f", cmap="coolwarm", annot_kws={"fontsize": 9}, vmin=0, vmax=1)
plt.title('Matriz de correlación de características', fontdict = font_e)
plt.xticks(rotation=90, font= font_l)
plt.yticks(rotation=0, font = font_l)
plt.show()

"""#Se muestran los elementos más correlacionados"""

# ordenar la columna "popularity" de la matriz de correlación de manera descendente
corr_class = matriz_corr['popularity'].sort_values(ascending=False)

# imprimir las características más correlacionadas con popularity
print(corr_class)

"""#Se muestran las estadisticas de los atributos"""

estadisticas(spotify_data)

"""#Se crea una función que entregue los histogramas de todo el Dataframe"""

histogramas(spotify_data)

x=spotify_data.iloc[:,2].to_frame()
y=spotify_data.iloc[:,0]

x

y

plt.scatter(x,y)

# Agregar etiquetas y título al gráfico
plt.xlabel('Variable predictora (x)')
plt.ylabel('Variable objetivo (y)')
plt.title('Gráfico de dispersión de x vs. y')

# Mostrar el gráfico
plt.show()

"""#Se dividen los datos 60/20/20 para entrenar los modelos"""

# Dividir los datos en características y etiquetas
X = spotify_data.iloc[:, 1:]
y = spotify_data.iloc[:, 0]

# Dividir los datos en conjuntos de entrenamiento (60%), validación (20%) y prueba (20%)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)
X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5)

"""#Normalización de los datos"""

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_val = scaler.transform(X_val)
X_test = scaler.transform(X_test)

"""# Regresion Lineal"""

# Crear el modelo de regresión lineal
regression_model = LinearRegression()

# Medir el tiempo de entrenamiento
start_time = time.time()
regression_model.fit(X_train, y_train)
training_time = time.time() - start_time

# Realizar predicciones en el conjunto de validación
y_val_pred = regression_model.predict(X_val)

# Calcular métricas de desempeño en el conjunto de validación
mse_val = mean_squared_error(y_val, y_val_pred)
rmse_val = mean_squared_error(y_val, y_val_pred, squared=False)
mae_val = mean_absolute_error(y_val, y_val_pred)
r2_val = r2_score(y_val, y_val_pred)

# Realizar predicciones en el conjunto de prueba
y_test_pred = regression_model.predict(X_test)

# Calcular métricas de desempeño en el conjunto de prueba
mse_test = mean_squared_error(y_test, y_test_pred)
rmse_test = mean_squared_error(y_test, y_test_pred, squared=False)
mae_test = mean_absolute_error(y_test, y_test_pred)
r2_test = r2_score(y_test, y_test_pred)

# Crear un DataFrame con los resultados
results_df_1 = pd.DataFrame({
    'Métrica': ['MSE', 'RMSE', 'MAE', 'R²', 'Tiempo de Entrenamiento'],
    'Conjunto de Validación': [mse_val, rmse_val, mae_val, r2_val, '-'],
    'Conjunto de Prueba': [mse_test, rmse_test, mae_test, r2_test, '-']
})

# Agregar el tiempo de entrenamiento a la tabla
results_df_1.at[4, 'Conjunto de Validación'] = '-'
results_df_1.at[4, 'Conjunto de Prueba'] = training_time

print(results_df_1)
print('')

plt.hist([y_test, y_val_pred], bins=10, color=['blue', 'orange'], label=['y_test', 'y_pred'])

# Añadir etiquetas y leyendas
plt.xlabel('Valores')
plt.ylabel('Frecuencia')
plt.legend()

# Mostrar el gráfico
plt.show()

"""# Gradient Boosting"""

# Crear el modelo de Regresión de Gradiente
gradient_boosting_model = GradientBoostingRegressor()

# Medir el tiempo de entrenamiento
start_time = time.time()
gradient_boosting_model.fit(X_train, y_train)
training_time = time.time() - start_time

# Realizar predicciones en el conjunto de validación
y_val_pred = gradient_boosting_model.predict(X_val)

# Calcular métricas de desempeño en el conjunto de validación
mse_val = mean_squared_error(y_val, y_val_pred)
rmse_val = mean_squared_error(y_val, y_val_pred, squared=False)
mae_val = mean_absolute_error(y_val, y_val_pred)
r2_val = r2_score(y_val, y_val_pred)

# Realizar predicciones en el conjunto de prueba
y_test_pred = gradient_boosting_model.predict(X_test)

# Calcular métricas de desempeño en el conjunto de prueba
mse_test = mean_squared_error(y_test, y_test_pred)
rmse_test = mean_squared_error(y_test, y_test_pred, squared=False)
mae_test = mean_absolute_error(y_test, y_test_pred)
r2_test = r2_score(y_test, y_test_pred)

# Crear un DataFrame con los resultados
results_df_4 = pd.DataFrame({
    'Métrica': ['MSE', 'RMSE', 'MAE', 'R²', 'Tiempo de Entrenamiento'],
    'Conjunto de Validación': [mse_val, rmse_val, mae_val, r2_val, '-'],
    'Conjunto de Prueba': [mse_test, rmse_test, mae_test, r2_test, '-']
})

# Agregar el tiempo de entrenamiento a la tabla
results_df_4.at[4, 'Conjunto de Validación'] = '-'
results_df_4.at[4, 'Conjunto de Prueba'] = training_time

print(results_df_4)
print('')

plt.hist([y_test, y_val_pred], bins=10, color=['blue', 'orange'], label=['y_test', 'y_pred'])

# Añadir etiquetas y leyendas
plt.xlabel('Valores')
plt.ylabel('Frecuencia')
plt.legend()

# Mostrar el gráfico
plt.show()

"""# XGBoost"""

# Crear el modelo de XGBoost para regresión
xgb_model = xgb.XGBRegressor()

# Medir el tiempo de entrenamiento
start_time = time.time()
xgb_model.fit(X_train, y_train)
training_time = time.time() - start_time

# Realizar predicciones en el conjunto de validación
y_val_pred = xgb_model.predict(X_val)

# Calcular métricas de desempeño en el conjunto de validación
mse_val = mean_squared_error(y_val, y_val_pred)
rmse_val = mean_squared_error(y_val, y_val_pred, squared=False)
mae_val = mean_absolute_error(y_val, y_val_pred)
r2_val = r2_score(y_val, y_val_pred)

# Realizar predicciones en el conjunto de prueba
y_test_pred = xgb_model.predict(X_test)

# Calcular métricas de desempeño en el conjunto de prueba
mse_test = mean_squared_error(y_test, y_test_pred)
rmse_test = mean_squared_error(y_test, y_test_pred, squared=False)
mae_test = mean_absolute_error(y_test, y_test_pred)
r2_test = r2_score(y_test, y_test_pred)

# Crear un DataFrame con los resultados
results_df_5 = pd.DataFrame({
    'Métrica': ['MSE', 'RMSE', 'MAE', 'R²', 'Tiempo de Entrenamiento'],
    'Conjunto de Validación': [mse_val, rmse_val, mae_val, r2_val, '-'],
    'Conjunto de Prueba': [mse_test, rmse_test, mae_test, r2_test, '-']
})

# Agregar el tiempo de entrenamiento a la tabla
results_df_5.at[4, 'Conjunto de Validación'] = '-'
results_df_5.at[4, 'Conjunto de Prueba'] = training_time

print(results_df_5)
print('')

plt.hist([y_test, y_val_pred], bins=10, color=['blue', 'orange'], label=['y_test', 'y_pred'])

# Añadir etiquetas y leyendas
plt.xlabel('Valores')
plt.ylabel('Frecuencia')
plt.legend()

# Mostrar el gráfico
plt.show()

"""# PCA"""

# Aplicar PCA para reducir la dimensionalidad del conjunto de entrenamiento
pca = PCA(n_components=10)
X_train_pca = pca.fit_transform(X_train)
X_val_pca = pca.transform(X_val)
X_test_pca = pca.transform(X_test)

"""# SVR"""

# Crear el modelo de Máquinas de Soporte Vectorial con Regresión (SVR)
svr_model = SVR()

# Medir el tiempo de entrenamiento
start_time = time.time()
svr_model.fit(X_train, y_train)
training_time = time.time() - start_time

# Realizar predicciones en el conjunto de validación
y_val_pred = svr_model.predict(X_val)

# Calcular métricas de desempeño en el conjunto de validación
mse_val = mean_squared_error(y_val, y_val_pred)
rmse_val = mean_squared_error(y_val, y_val_pred, squared=False)
mae_val = mean_absolute_error(y_val, y_val_pred)
r2_val = r2_score(y_val, y_val_pred)

# Realizar predicciones en el conjunto de prueba
y_test_pred = svr_model.predict(X_test)

# Calcular métricas de desempeño en el conjunto de prueba
mse_test = mean_squared_error(y_test, y_test_pred)
rmse_test = mean_squared_error(y_test, y_test_pred, squared=False)
mae_test = mean_absolute_error(y_test, y_test_pred)
r2_test = r2_score(y_test, y_test_pred)

# Crear un DataFrame con los resultados
results_df_7 = pd.DataFrame({
    'Métrica': ['MSE', 'RMSE', 'MAE', 'R²', 'Tiempo de Entrenamiento'],
    'Conjunto de Validación': [mse_val, rmse_val, mae_val, r2_val, '-'],
    'Conjunto de Prueba': [mse_test, rmse_test, mae_test, r2_test, '-']
})

# Agregar el tiempo de entrenamiento a la tabla
results_df_7.at[4, 'Conjunto de Validación'] = '-'
results_df_7.at[4, 'Conjunto de Prueba'] = training_time

print(results_df_7)
print('')

plt.hist([y_test, y_val_pred], bins=10, color=['blue', 'orange'], label=['y_test', 'y_pred'])

# Añadir etiquetas y leyendas
plt.xlabel('Valores')
plt.ylabel('Frecuencia')
plt.legend()

# Mostrar el gráfico
plt.show()

"""# Random Forest"""

# Crear el modelo de Bosque Aleatorio
random_forest_model = RandomForestRegressor()

# Medir el tiempo de entrenamiento
start_time = time.time()
random_forest_model.fit(X_train, y_train)
training_time = time.time() - start_time

# Realizar predicciones en el conjunto de validación
y_val_pred = random_forest_model.predict(X_val)

# Calcular métricas de desempeño en el conjunto de validación
mse_val = mean_squared_error(y_val, y_val_pred)
rmse_val = mean_squared_error(y_val, y_val_pred, squared=False)
mae_val = mean_absolute_error(y_val, y_val_pred)
r2_val = r2_score(y_val, y_val_pred)

# Realizar predicciones en el conjunto de prueba
y_test_pred = random_forest_model.predict(X_test)

# Calcular métricas de desempeño en el conjunto de prueba
mse_test = mean_squared_error(y_test, y_test_pred)
rmse_test = mean_squared_error(y_test, y_test_pred, squared=False)
mae_test = mean_absolute_error(y_test, y_test_pred)
r2_test = r2_score(y_test, y_test_pred)

# Crear un DataFrame con los resultados
results_df_9 = pd.DataFrame({
    'Métrica': ['MSE', 'RMSE', 'MAE', 'R²', 'Tiempo de Entrenamiento'],
    'Conjunto de Validación': [mse_val, rmse_val, mae_val, r2_val, '-'],
    'Conjunto de Prueba': [mse_test, rmse_test, mae_test, r2_test, '-']
})

# Agregar el tiempo de entrenamiento a la tabla
results_df_9.at[4, 'Conjunto de Validación'] = '-'
results_df_9.at[4, 'Conjunto de Prueba'] = training_time

print(results_df_9)
print('')

plt.hist([y_test, y_val_pred], bins=10, color=['blue', 'orange'], label=['y_test', 'y_pred'])

# Añadir etiquetas y leyendas
plt.xlabel('Valores')
plt.ylabel('Frecuencia')
plt.legend()

# Mostrar el gráfico
plt.show()

"""# Resultados"""

# Agregar una columna con el número del modelo en cada dataframe de resultados
results_df_1['Modelo'] = 'R L'
results_df_4['Modelo'] = 'G B'
results_df_5['Modelo'] = 'XGB'
results_df_7['Modelo'] = 'SVR'
results_df_9['Modelo'] = 'R F'

# Concatenar todos los dataframes en uno solo
all_results_df = pd.concat([results_df_1, results_df_4, results_df_5, results_df_7, results_df_9], ignore_index=True)

# Mostrar el dataframe con todos los resultados
print(all_results_df)